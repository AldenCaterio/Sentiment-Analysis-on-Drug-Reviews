{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/TAlkam/Sentiment-Analysis-on-Drug-Reviews/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of_m8lhW16mN"
   },
   "source": [
    "Let's load these files and take a look at the data. We'll start with the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "fDRRIcdAVSK5",
    "outputId": "3c3c7b55-f84e-472b-d534-1893f19d4304"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom google.colab import files\\n\\nuploaded = files.upload()\\n\\nfor fn in uploaded.keys():\\n  print(\\'User uploaded file \"{name}\" with length {length} bytes\\'.format(\\n      name=fn, length=len(uploaded[fn])))\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "kBOZlepiW4TR",
    "outputId": "248d3095-047f-4e6e-d65f-1962b6799e70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom google.colab import files\\n\\nuploaded = files.upload()\\n\\nfor fn in uploaded.keys():\\n  print(\\'User uploaded file \"{name}\" with length {length} bytes\\'.format(\\n      name=fn, length=len(uploaded[fn])))\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JGoS0tIbV2OJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data into pandas DataFrames\n",
    "train_df = pd.read_csv('drugLibTrain_raw.tsv', delimiter='\\t')\n",
    "test_df = pd.read_csv('drugLibTest_raw.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Jjpu3T53CJF"
   },
   "source": [
    " **Let's get an overview of the dataset including the column names, total number of entries, and the data type of each column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPKjHjZs3Cm2",
    "outputId": "6b13914c-b790-46db-9c21-915fda7f885a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3107 entries, 0 to 3106\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Unnamed: 0         3107 non-null   int64 \n",
      " 1   urlDrugName        3107 non-null   object\n",
      " 2   rating             3107 non-null   int64 \n",
      " 3   effectiveness      3107 non-null   object\n",
      " 4   sideEffects        3107 non-null   object\n",
      " 5   condition          3106 non-null   object\n",
      " 6   benefitsReview     3107 non-null   object\n",
      " 7   sideEffectsReview  3105 non-null   object\n",
      " 8   commentsReview     3099 non-null   object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 218.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Information about the training dataset\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIZ04vDM2aWR"
   },
   "source": [
    "**Add sentiment labels**\n",
    "\n",
    "Since the data does not come with predefined sentiment labels, we will need to define our own rules for labeling the sentiments. One approach could be to use the numerical rating feature to infer sentiment:\n",
    "\n",
    "We can define ratings of 7-10 as '**positive**',\n",
    "Ratings of 4-6 as '**neutral**',\n",
    "And ratings of 1-3 as '**negative**'.\n",
    "Alternatively, we could use the effectiveness and sideEffects categorical features to derive sentiment labels. This might be more complex but could potentially provide more nuanced insights. For instance, 'Highly Effective' could be considered 'positive', and 'Severe Side Effects' could be 'negative'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HTMmG39mXBiJ"
   },
   "outputs": [],
   "source": [
    "# Define a function to convert ratings into sentiment labels\n",
    "def rating_to_sentiment(rating):\n",
    "    if rating >= 7:\n",
    "        return 'positive'\n",
    "    elif rating <= 3:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the function to the rating column of both dataframes\n",
    "train_df['sentiment'] = train_df['rating'].apply(rating_to_sentiment)\n",
    "test_df['sentiment'] = test_df['rating'].apply(rating_to_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgZPAmpf4aIt"
   },
   "source": [
    "**Preprocess the text**\n",
    "Before running this part, We need to install and import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OM6gRvcTXOTP",
    "outputId": "68f3b718-f2a0-4d59-a288-ca0c35900f4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alden\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alden\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alden\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\alden\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4') # Added to fix error\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlHdYcXc4xTV"
   },
   "source": [
    "**Proceed with the text preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Qre4lNXhXjXL"
   },
   "outputs": [],
   "source": [
    "# Define a lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define the English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define a function to clean, tokenize, remove stop-words, and lemmatize text\n",
    "def preprocess_text(text):\n",
    "    # Check if the text is not a string (possibly NaN), and if so, replace it with an empty string\n",
    "    if not isinstance(text, str):\n",
    "        text = ''\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation, numbers, and special characters\n",
    "    text = re.sub(r'[^a-z ]', '', text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize the tokens\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    # Join the tokens back into a single string and return it\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Combine the review columns into a single column and preprocess the text\n",
    "train_df['combined_review'] = (train_df['benefitsReview'].fillna('') + ' ' +\n",
    "                               train_df['sideEffectsReview'].fillna('') + ' ' +\n",
    "                               train_df['commentsReview'].fillna('')).apply(preprocess_text)\n",
    "test_df['combined_review'] = (test_df['benefitsReview'].fillna('') + ' ' +\n",
    "                              test_df['sideEffectsReview'].fillna('') + ' ' +\n",
    "                              test_df['commentsReview'].fillna('')).apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhTz4YUaYhP-"
   },
   "source": [
    "**1. Exploratory Data Analysis (EDA):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "id": "uzMpdHUtYls0",
    "outputId": "e210754a-9e0f-434b-ed92-43d9f32577d9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=train_df, x='sentiment', palette='viridis')\n",
    "plt.xlabel('Sentiment', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.title('Distribution of Sentiments in the Dataset', fontsize=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tK31iRcYql0"
   },
   "source": [
    "**2. Vectorization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3kIFkUEeYxjN"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train = vectorizer.fit_transform(train_df['combined_review'])\n",
    "X_test = vectorizer.transform(test_df['combined_review'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqltUE1MY2i1"
   },
   "source": [
    "**3. Model Training and Evaluation: Train a Naive Bayes classifier, predict on the test set, and evaluate the predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rbRWY6iY7eF",
    "outputId": "f397e92c-93ea-44ec-a5d2-0ed3538540b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.09      0.16       197\n",
      "           1       0.00      0.00      0.00       169\n",
      "           2       0.66      1.00      0.79       670\n",
      "\n",
      "    accuracy                           0.66      1036\n",
      "   macro avg       0.52      0.36      0.32      1036\n",
      "weighted avg       0.60      0.66      0.54      1036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Label encoding for the target variable\n",
    "y_train = train_df['sentiment'].replace({'positive': 2, 'neutral': 1, 'negative': 0})\n",
    "y_test = test_df['sentiment'].replace({'positive': 2, 'neutral': 1, 'negative': 0})\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred, zero_division=0)) # zero_division=0 to get rid of warnings\n",
    "# UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.09      0.16       197\n",
      "           1       1.00      0.00      0.00       169\n",
      "           2       0.66      1.00      0.79       670\n",
      "\n",
      "    accuracy                           0.66      1036\n",
      "   macro avg       0.85      0.36      0.32      1036\n",
      "weighted avg       0.76      0.66      0.54      1036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Label encoding for the target variable\n",
    "y_train = train_df['sentiment'].replace({'positive': 2, 'neutral': 1, 'negative': 0})\n",
    "y_test = test_df['sentiment'].replace({'positive': 2, 'neutral': 1, 'negative': 0})\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred, zero_division=1)) # zero_division=1 results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doYxIUmPlR3o"
   },
   "source": [
    "The labels 0, 1, and 2 represent 'negative', 'neutral', and 'positive' sentiments, respectively. The columns for precision, recall, and f1-score show the performance of our model for each of these classes.\n",
    "\n",
    "Negative sentiment (0): The model has a high precision (0.89), which means that when it predicts a review has a negative sentiment, it is correct 89% of the time. However, the recall is very low (0.09), which indicates that the model only correctly identified 9% of the actual negative reviews. The f1-score, which balances precision and recall, is low (0.16) due to the low recall. The model seems to struggle with identifying negative reviews.\n",
    "\n",
    "Neutral sentiment (1): The model has a precision, recall, and f1-score of 0. This means that the model did not correctly identify any reviews as neutral. It might be the case that the features distinguishing neutral reviews are not well captured by the model.\n",
    "\n",
    "Positive sentiment (2): The model performs best in identifying positive reviews. It has a precision of 0.66 and a recall of 1.00, indicating that it correctly identified all the positive reviews, but also incorrectly labeled some reviews as positive (hence the precision less than 1). The high f1-score (0.79) reflects this strong performance.\n",
    "\n",
    "The overall accuracy of our model is 0.66, which means it correctly predicts the sentiment 66% of the time.\n",
    "\n",
    "However, given the low performance for negative and neutral classes, we can consider strategies to improve our model's performance. These could include:\n",
    "\n",
    "Feature engineering: we could try to create new features that might help the model distinguish between the classes better. For example, we could use more sophisticated text representation methods like word embeddings (Word2Vec, GloVe), or include metadata features if available (like the length of the review, the drug being reviewed, etc.).\n",
    "\n",
    "Class balancing techniques: If our classes are imbalanced (i.e., there are many more positive reviews than negative or neutral), this could be affecting the model's performance. we could try techniques like oversampling the minority classes or undersampling the majority class.\n",
    "\n",
    "Model tuning: we could try adjusting the parameters of our model to see if we can improve performance. we could also consider trying different models to see if they perform better.\n",
    "\n",
    "Ensemble methods: we could try combining multiple models to make predictions. This often results in better performance than any single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWpS42qh9lvK"
   },
   "source": [
    "**4. The AUC-ROC value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UwRqnwu9mHv",
    "outputId": "5bd798db-bc95-4028-a39b-e02bb36def56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.52\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "auc = multiclass_roc_auc_score(y_test, y_pred)\n",
    "print('AUC-ROC:', round(auc, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APye1Oj1-BWO"
   },
   "source": [
    "The AUC-ROC value ranges from 0 to 1. An AUC-ROC value of 0.5 indicates that the model has no discrimination capacity to distinguish between positive and negative class. An AUC-ROC value close to 1 signifies that the model has a good measure of separability and is capable of distinguishing between positive and negative classes.\n",
    "\n",
    "The AUC-ROC score of 0.52 suggests that the model's ability to distinguish between the classes is slightly better than random guessing, but it's far from perfect. There's certainly room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oR0492YZAPIw"
   },
   "source": [
    "**Let's train and evaluate a Support Vector Machines (SVM) classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUbIWSM5lSVK",
    "outputId": "f1f2f0f4-0f28-4553-b0fd-bd89af40cbce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55       197\n",
      "           1       0.34      0.10      0.16       169\n",
      "           2       0.74      0.90      0.81       670\n",
      "\n",
      "    accuracy                           0.70      1036\n",
      "   macro avg       0.56      0.51      0.51      1036\n",
      "weighted avg       0.65      0.70      0.66      1036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Support Vector Classifier\n",
    "svm_classifier = LinearSVC()\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's train and evaluate a Support Vector Machines (SVM) classifier with a K-Folds cross-validator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Folds cross validation method splits the data into k equal parts, or folds. The training set consists of k-1 folds while the test set consists of the remaining fold. Fitting the model is done on each iteration until all folds have been used as the test set. Finding the average accuracy (score) of all the folds results in a more robust solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier with cross validation (K-Fold method)\n",
      "Fold = 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.51      0.51       138\n",
      "     neutral       0.34      0.12      0.18       129\n",
      "    positive       0.76      0.87      0.81       562\n",
      "\n",
      "    accuracy                           0.70       829\n",
      "   macro avg       0.54      0.50      0.50       829\n",
      "weighted avg       0.66      0.70      0.67       829\n",
      "\n",
      "Fold = 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.37      0.45       147\n",
      "     neutral       0.20      0.11      0.14       101\n",
      "    positive       0.78      0.91      0.84       581\n",
      "\n",
      "    accuracy                           0.71       829\n",
      "   macro avg       0.51      0.46      0.48       829\n",
      "weighted avg       0.67      0.71      0.68       829\n",
      "\n",
      "Fold = 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.54      0.57       153\n",
      "     neutral       0.12      0.09      0.11        98\n",
      "    positive       0.79      0.84      0.81       578\n",
      "\n",
      "    accuracy                           0.70       829\n",
      "   macro avg       0.50      0.49      0.49       829\n",
      "weighted avg       0.67      0.70      0.68       829\n",
      "\n",
      "Fold = 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.48      0.54       154\n",
      "     neutral       0.34      0.12      0.17       130\n",
      "    positive       0.75      0.91      0.82       544\n",
      "\n",
      "    accuracy                           0.71       828\n",
      "   macro avg       0.57      0.50      0.51       828\n",
      "weighted avg       0.66      0.71      0.67       828\n",
      "\n",
      "Fold = 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.55      0.59       159\n",
      "     neutral       0.39      0.13      0.19       134\n",
      "    positive       0.75      0.91      0.82       535\n",
      "\n",
      "    accuracy                           0.71       828\n",
      "   macro avg       0.59      0.53      0.53       828\n",
      "weighted avg       0.67      0.71      0.67       828\n",
      "\n",
      "Average Accuracy for 5 folds = 0.7048049859268195\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Combine training and testing data to form 1 dataset\n",
    "combined_df = pd.concat([train_df,test_df], ignore_index=True)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "combined_X = vectorizer.fit_transform(combined_df['combined_review'])\n",
    "combined_y = combined_df['sentiment']\n",
    "\n",
    "# Initialize k-fold model\n",
    "num_splits = 5\n",
    "kf = KFold(n_splits=num_splits)\n",
    "\n",
    "# Support Vector Classifier\n",
    "svm_classifier = LinearSVC()\n",
    "\n",
    "# Initialize lists/variables\n",
    "accuracy = []\n",
    "num_folds = 1\n",
    "\n",
    "print(\"SVM Classifier with cross validation (K-Fold method)\")\n",
    "for train_index, test_index in kf.split(combined_X):\n",
    "    print(f\"Fold = {num_folds}\")\n",
    "    \n",
    "    # Split the data based on the new fold\n",
    "    X_train_kfold, X_test_kfold = combined_X[train_index], combined_X[test_index]\n",
    "    y_train_kfold, y_test_kfold = combined_y[train_index], combined_y[test_index]\n",
    "    \n",
    "    # Fit the training data\n",
    "    svm_classifier.fit(X_train_kfold, y_train_kfold)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_svm = svm_classifier.predict(X_test_kfold)\n",
    "    \n",
    "    # Evaluation\n",
    "    print(classification_report(y_test_kfold, y_pred_svm))\n",
    "    accuracy.append(svm_classifier.score(X_test_kfold, y_test_kfold))\n",
    "    \n",
    "    num_folds=num_folds+1\n",
    "\n",
    "# Average accuracy over number of folds (num_splits)\n",
    "avg_accuracy = np.mean(accuracy)\n",
    "print(f\"Average Accuracy for {num_splits} folds = {avg_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMui_vQmmioh"
   },
   "source": [
    "Let's interpret the results of the SVM Classifiers:\n",
    "\n",
    "Negative sentiment (0): The overall precision is around 0.61 and seems to increase as support increases. In other words, the more samples that were actually negative, the better the model performed when identifying negatives. The overall recall, the percentage of correct predicitions relative to the true number of negatives, also increased slightly as support increased. The overall F1-score is around 0.53.\n",
    "\n",
    "Neutral sentiment (1): The overall precision varies quite a bit. This might be due to the high variance in support with a minimum of 98 in fold 3 and a maximum of 134 in fold 5. The overall precision averages at around 0.27, which means that it correctly identifies a neutral review 27% of the time when the review is truly neutral. The recall stays relatively the same around 0.11, meaning the model only correctly identifies 11% of actual neutral reviews. The F1-score doesn't vary too much, staying around 0.16.\n",
    "\n",
    "Positive sentiment (2): The model performs best when identifying positive reviews. The overall precision is around 0.76, the overall recall is around 0.89, and the overall F1-score is around 0.82. The F1-score is close to 1, signifying an accurate model.\n",
    "\n",
    "The overall accuracy of the model is 0.70, which means it correctly predicts the sentiment 70% of the time. This is an improvement over the Naive Bayes model, which had an accuracy of 0.66.\n",
    "\n",
    "When comparing the overall results from the cross-validated SVM model to the results from the initial SVM model with no cross-validation, there does not seem to be too much difference. However, inspecting the individual folds of the cross-validated model can give more insight about how using different splits for the training and testing data can affect results. In folds where there were less samples for a neutral sentiment, the precision varies widely. This alludes to how the quantity of the data affects the results. \n",
    "\n",
    "The SVM model seems to be performing better than the Naive Bayes model, especially for negative sentiments. However, both models struggle with the neutral class. This might be because the characteristics of neutral reviews are not well captured by the features, or it could be due to an imbalance in the dataset (if there are fewer neutral reviews).\n",
    "\n",
    "Next steps could include further tuning the SVM model, trying different features, or trying a different type of model. Given that the data contains sequence information (it is text data), a model that can capture this sequential nature, like a Recurrent Neural Network (RNN), might be able to perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Jo_YU2vBKMK"
   },
   "source": [
    "Now that we've trained and evaluated a SVM model, the next step is to experiment with a deep learning model - Recurrent Neural Network (RNN) model for our sentiment analysis task.\n",
    "\n",
    "RNNs are a type of neural network that are great for sequential data, like text, because they have \"memory\" - they take as their input not just the current input, but also what they have perceived previously in time.\n",
    "\n",
    "However, setting up and training an RNN (especially on text data) can be quite complex and computationally expensive. It involves several additional steps such as:\n",
    "\n",
    "**Tokenization:** Converting the text into a sequence of integers (tokens).\n",
    "**Padding:** Making sure all the sequences are the same length by padding shorter ones with zeros.\n",
    "**Creating an embedding layer:** This is a layer in the neural network that converts the tokens into dense vectors of fixed size that the network can learn from. It's a way to reduce the dimensionality of the input data. **Building the RNN model:** This involves defining the architecture of the model. For example, we use an LSTM (Long Short-Term Memory) or GRU (Gated Recurrent Unit) layer, which are special types of RNN layers that can better capture long-term dependencies in the data.\n",
    "**Training the model:** This is the process of feeding our data through the network and updating the weights of the network to minimize the prediction error.\n",
    "**Evaluating the model:** This is similar to what we did with the SVM and Naive Bayes models - comparing the model's predictions on a test set to the actual labels to see how well the model is performing.\n",
    "\n",
    "All these steps require specific libraries and functions. In Python, the Keras library (which is part of TensorFlow) is commonly used for building and training RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_TTnqueCg5W"
   },
   "source": [
    "**Install Tensoflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VH9XxuC1mjEd",
    "outputId": "b1824820-5835-46e4-acaf-b4e3b6fe22f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from tensorflow) (65.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda3\\lib\\site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in d:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_V5bSq7CocS"
   },
   "source": [
    "**Install Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYSL9ChInz2w",
    "outputId": "dfff3231-3d9e-4017-a885-e9ef7550ec93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\slugg\\appdata\\roaming\\python\\python310\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\slugg\\anaconda3\\lib\\site-packages (2.12.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.1 in c:\\users\\slugg\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.12.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (22.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (1.56.2)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\slugg\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (0.4.14)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\slugg\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.1->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.1->tensorflow) (1.10.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9iKMuKHrdwM"
   },
   "source": [
    "**Let's train an RNN model using Keras**\n",
    "\n",
    "Let's train the Long Short-Term Memory (LSTM) model which is a type of Recurrent Neural Network (RNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdv0oKTRrcFE",
    "outputId": "9fc46d7b-e77d-4485-98f2-890ece17d3fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "98/98 [==============================] - 19s 149ms/step - loss: 0.8822 - accuracy: 0.6788 - val_loss: 0.8638 - val_accuracy: 0.6467\n",
      "Epoch 2/5\n",
      "98/98 [==============================] - 14s 139ms/step - loss: 0.7045 - accuracy: 0.7258 - val_loss: 0.7968 - val_accuracy: 0.6795\n",
      "Epoch 3/5\n",
      "98/98 [==============================] - 14s 145ms/step - loss: 0.5138 - accuracy: 0.7979 - val_loss: 0.9127 - val_accuracy: 0.6844\n",
      "Epoch 4/5\n",
      "98/98 [==============================] - 14s 144ms/step - loss: 0.3968 - accuracy: 0.8375 - val_loss: 1.0495 - val_accuracy: 0.6766\n",
      "Epoch 5/5\n",
      "98/98 [==============================] - 16s 169ms/step - loss: 0.2750 - accuracy: 0.8935 - val_loss: 1.2744 - val_accuracy: 0.6535\n",
      "33/33 [==============================] - 2s 52ms/step - loss: 1.2744 - accuracy: 0.6535\n",
      "Test Loss: 1.27\n",
      "Test Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Maximum number of words to keep based on word frequency\n",
    "max_words = 5000\n",
    "\n",
    "# Maximum length of the sequences\n",
    "max_len = 100\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_df['combined_review'])\n",
    "sequences_train = tokenizer.texts_to_sequences(train_df['combined_review'])\n",
    "sequences_test = tokenizer.texts_to_sequences(test_df['combined_review'])\n",
    "\n",
    "# Padding\n",
    "X_train = pad_sequences(sequences_train, maxlen=max_len)\n",
    "X_test = pad_sequences(sequences_test, maxlen=max_len)\n",
    "\n",
    "# Labels\n",
    "y_train = train_df['sentiment'].replace({'positive': 2, 'neutral': 1, 'negative': 0}).values\n",
    "y_test = test_df['sentiment'].replace({'positive': 2, 'neutral': 1, 'negative': 0}).values\n",
    "\n",
    "# Building the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes: positive, neutral, negative\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluating the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', round(loss, 2))\n",
    "print('Test Accuracy:', round(accuracy, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEIQE9ObtQIc"
   },
   "source": [
    "**Here's a breakdown of the output:**\n",
    "\n",
    "**Epochs:** we trained the model for 5 epochs. In each epoch, the model went through the entire training dataset once.\n",
    "\n",
    "**Training Loss and Accuracy:** These values represent how well our model is doing on the training data. The training loss decreased with each epoch, which is a good sign. It means the model's predictions are getting closer to the actual values. The accuracy increased with each epoch, which indicates the model is correctly classifying a higher percentage of reviews.\n",
    "\n",
    "**Validation Loss and Accuracy:** These values represent how well our model is expected to perform on unseen data, based on its performance on the validation set. Ideally, we want the validation loss to decrease and the validation accuracy to increase, just like the training metrics. However, in this case, the validation loss increased and the validation accuracy didn't improve significantly. This may indicate overfitting, meaning the model is fitting the training data too closely and not generalizing well to new data.\n",
    "\n",
    "**Test Loss and Accuracy:** After training, we evaluated the model on the test set, which it hadn't seen before. The test loss and accuracy give us an unbiased estimate of how our model will perform on new data. In this case, the test accuracy is approximately 67.7%, meaning the model correctly classified about 67.7% of the reviews in the test set.\n",
    "\n",
    "Overall, our LSTM model has learned to classify the sentiment of drug reviews with a reasonable degree of accuracy. However, there's likely room for improvement. At this time, we want to experiment with different model architectures, add regularization techniques (like dropout), or try different hyperparameters to improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "By5nFJuzHZMz"
   },
   "source": [
    "**Add More LSTM Layers:** Stacking LSTM layers can often lead to better performance. We can add another LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "r6TJwzK2tQrD"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\n",
    "model.add(LSTM(64, return_sequences=True))  # return_sequences must be True for stacking\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gl9yq1SdtShI"
   },
   "source": [
    "**Change the LSTM to a Bidirectional LSTM:** Bidirectional LSTMs can capture patterns from both the beginning and end of a sequence, which can be helpful in understanding the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "_KSj7ZoOtS4F"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA_TsiSwti2V"
   },
   "source": [
    "**Use a Different Type of RNN:** We try using a Gated Recurrent Unit (GRU) instead of an LSTM. GRUs are a variation of LSTMs that are a bit simpler and can sometimes perform just as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_P75JqUrtjMv"
   },
   "outputs": [],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKH5UGntts4-"
   },
   "source": [
    "**Add More Dense Layers:** We also add more Dense layers to our model. This can sometimes improve performance, but it may also increase the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "esdEbdTottTs"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))  # additional Dense layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLEh3foguTBi"
   },
   "source": [
    "**Adding an extra LSTM layer: Update Model Architecture:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3bcgqf73uUig"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\n",
    "model.add(LSTM(64, return_sequences=True))  # First LSTM layer with return_sequences=True\n",
    "model.add(LSTM(64))  # Second LSTM layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes: positive, neutral, negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SOQ-YTcuZIH"
   },
   "source": [
    "**Train the Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTU0vGpQufht",
    "outputId": "ce24da4a-786d-4df0-fe56-5ef8b3dee84a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "98/98 [==============================] - 36s 280ms/step - loss: 0.8676 - accuracy: 0.6820 - val_loss: 0.8122 - val_accuracy: 0.6458\n",
      "Epoch 2/5\n",
      "98/98 [==============================] - 24s 245ms/step - loss: 0.6551 - accuracy: 0.7451 - val_loss: 0.7836 - val_accuracy: 0.6979\n",
      "Epoch 3/5\n",
      "98/98 [==============================] - 24s 244ms/step - loss: 0.4811 - accuracy: 0.8133 - val_loss: 0.9053 - val_accuracy: 0.7017\n",
      "Epoch 4/5\n",
      "98/98 [==============================] - 23s 239ms/step - loss: 0.3726 - accuracy: 0.8494 - val_loss: 0.9791 - val_accuracy: 0.6544\n",
      "Epoch 5/5\n",
      "98/98 [==============================] - 24s 241ms/step - loss: 0.2938 - accuracy: 0.8870 - val_loss: 1.4573 - val_accuracy: 0.6274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26836c82e00>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRr3PnwfvGI0"
   },
   "source": [
    "**Evaluate the Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCB6SiwTvHt4",
    "outputId": "94416fd4-c4ba-43b0-ee94-a630f777f98c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 3s 95ms/step - loss: 1.4573 - accuracy: 0.6274\n",
      "Test Loss: 1.46\n",
      "Test Accuracy: 0.63\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', round(loss, 2))\n",
    "print('Test Accuracy:', round(accuracy, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlbI1xk41bRZ"
   },
   "source": [
    "The test accuracy is approximately 63.51%, meaning the model correctly classified about 63.51% of the reviews in the test set. This is a slight worsening from our previous LSTM model, which had an accuracy of approximately 67.67%.  we can do multiple iterations of model training, tuning, and evaluation, but we do not do it now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-Htq7ldKSDZ"
   },
   "source": [
    "**Feature Engineering:**\n",
    "\n",
    "For using word embeddings (like Word2Vec or GloVe), we can use the gensim library. The embeddings can be used to replace the Embedding layer in our model. Here's a simple example with Word2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FUZ9VeA9pD0",
    "outputId": "59b35dfa-2e5f-49e2-f2f0-0ad1ca2aa14e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\slugg\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Collecting FuzzyTM>=0.4.0\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from gensim) (1.10.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.3)\n",
      "Collecting pyfume\n",
      "  Downloading pyFUME-0.2.25-py3-none-any.whl (67 kB)\n",
      "     ---------------------------------------- 67.1/67.1 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Collecting fst-pso\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting simpful\n",
      "  Downloading simpful-2.11.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\slugg\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Collecting miniful\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py): started\n",
      "  Building wheel for fst-pso (setup.py): finished with status 'done'\n",
      "  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20448 sha256=6595147691245d6ab74f046c02eb450deaf2115d6cd2d0a8db6ed28bb49e48a6\n",
      "  Stored in directory: c:\\users\\slugg\\appdata\\local\\pip\\cache\\wheels\\01\\02\\ee\\df0699282986903a384b69aab4413af9efd26b3612b5dccc9e\n",
      "  Building wheel for miniful (setup.py): started\n",
      "  Building wheel for miniful (setup.py): finished with status 'done'\n",
      "  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3522 sha256=b7036512ef37ba60c64c5c19292ad58f8ac26bcc25caf1e8ee3f68e44ea2a214\n",
      "  Stored in directory: c:\\users\\slugg\\appdata\\local\\pip\\cache\\wheels\\43\\aa\\48\\5c66b931ff013ad19774081aa19656637af5c0cc33b5494b30\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: simpful, miniful, fst-pso, pyfume, FuzzyTM\n",
      "Successfully installed FuzzyTM-2.0.5 fst-pso-1.8.1 miniful-0.0.6 pyfume-0.2.25 simpful-2.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\slugg\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "RS82oCKDFeks"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "1QETh3gMFs0F"
   },
   "outputs": [],
   "source": [
    "reviews = train_df['combined_review'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "7ePKd5wrGi0C"
   },
   "outputs": [],
   "source": [
    "decoded_reviews = [review.lower().split() for review in reviews]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTOsMaEgGmEh",
    "outputId": "331ae2bf-073f-44cb-8f9f-6ebb17ec57d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1721839, 1897610)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = train_df['combined_review'].values.tolist()\n",
    "decoded_reviews = [review.lower().split() for review in reviews]\n",
    "w2v_model = Word2Vec(decoded_reviews, vector_size=64, window=5, min_count=1, workers=4)\n",
    "w2v_model.train(decoded_reviews, total_examples=w2v_model.corpus_count, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlICXMKvMEdA",
    "outputId": "b82be405-a412-4cbc-e69f-b9c8b92a9651"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=64, input_length=max_len))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Train a Word2Vec model on our corpus\n",
    "w2v_model = Word2Vec(decoded_reviews, vector_size=64, window=5, min_count=1, workers=4)\n",
    "w2v_model.train(decoded_reviews, total_examples=w2v_model.corpus_count, epochs=10)\n",
    "\n",
    "# Get the word vectors from the trained Word2Vec model\n",
    "embedding_matrix = np.zeros((5000, 64))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < 5000:\n",
    "        if word in w2v_model.wv:\n",
    "            embedding_matrix[i] = w2v_model.wv[word]\n",
    "\n",
    "# Use the word vectors as weights in our Embedding layer\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlshA6yRLvE7",
    "outputId": "7e6414a2-03eb-407e-aec7-7bab62b46e10"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=64, input_length=max_len))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Train a Word2Vec model on our corpus\n",
    "w2v_model = Word2Vec(decoded_reviews, vector_size=64, window=5, min_count=1, workers=4)\n",
    "w2v_model.train(decoded_reviews, total_examples=w2v_model.corpus_count, epochs=10)\n",
    "\n",
    "# Get the word vectors from the trained Word2Vec model\n",
    "embedding_matrix = np.zeros((5000, 64))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < 5000:\n",
    "        if word in w2v_model.wv:\n",
    "            embedding_matrix[i] = w2v_model.wv[word]\n",
    "\n",
    "# Use the word vectors as weights in our Embedding layer\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLW-WwwGMlnl",
    "outputId": "c3bc2129-0b00-4879-8992-a58d3bef0ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "98/98 [==============================] - 17s 138ms/step - loss: 0.8685 - accuracy: 0.6704 - val_loss: 0.8644 - val_accuracy: 0.6467\n",
      "Epoch 2/5\n",
      "98/98 [==============================] - 12s 120ms/step - loss: 0.8249 - accuracy: 0.6859 - val_loss: 0.8676 - val_accuracy: 0.6477\n",
      "Epoch 3/5\n",
      "98/98 [==============================] - 10s 106ms/step - loss: 0.8118 - accuracy: 0.6855 - val_loss: 0.8366 - val_accuracy: 0.6496\n",
      "Epoch 4/5\n",
      "98/98 [==============================] - 11s 108ms/step - loss: 0.8013 - accuracy: 0.6862 - val_loss: 0.8909 - val_accuracy: 0.6274\n",
      "Epoch 5/5\n",
      "98/98 [==============================] - 11s 109ms/step - loss: 0.7800 - accuracy: 0.6952 - val_loss: 0.8283 - val_accuracy: 0.6573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26841c41e40>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert our labels to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uo8YUO7mNJia",
    "outputId": "c06e6cd5-a570-4e81-e98d-cb42b665c3c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 854ms/step\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Assume `new_review` is our new text data\n",
    "new_review = [\"This is a review of the drug\"]\n",
    "\n",
    "# Tokenize the new review\n",
    "sequences_new = tokenizer.texts_to_sequences(new_review)\n",
    "\n",
    "# Pad the new review\n",
    "padded_new = pad_sequences(sequences_new, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Make a prediction\n",
    "pred = model.predict(padded_new)\n",
    "\n",
    "# The prediction will be a 3-element vector representing the probabilities of the review being 'negative', 'neutral', and 'positive'.\n",
    "# To get the class with the highest probability, we can use the `np.argmax()` function.\n",
    "sentiment = np.argmax(pred)\n",
    "\n",
    "print(sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "KxeSs8McPFmw"
   },
   "outputs": [],
   "source": [
    "train_df['combined_review'] = train_df['benefitsReview'] + \" \" + train_df['sideEffectsReview'] + \" \" + train_df['commentsReview']\n",
    "test_df['combined_review'] = test_df['benefitsReview'] + \" \" + test_df['sideEffectsReview'] + \" \" + test_df['commentsReview']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ch_6a-x7QK2_",
    "outputId": "02ac8f09-2466-4730-9f18-dd871313e549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_df['combined_review'].isna().sum())\n",
    "print(test_df['combined_review'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "eAuoj3PjS-Cv"
   },
   "outputs": [],
   "source": [
    "# Find the length of reviews\n",
    "review_length = [len(review) for review in sequences_train]\n",
    "\n",
    "# Find the maximum length\n",
    "max_len = max(review_length)\n",
    "\n",
    "# Now pad the sequences\n",
    "X_train_pad = pad_sequences(sequences_train, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(sequences_test, maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "mcSWIaJ1SvpI"
   },
   "outputs": [],
   "source": [
    "# Convert the 'combined_review' column to string\n",
    "train_df['combined_review'] = train_df['combined_review'].astype(str)\n",
    "test_df['combined_review'] = test_df['combined_review'].astype(str)\n",
    "\n",
    "# Now, tokenize and pad the training data\n",
    "sequences_train = tokenizer.texts_to_sequences(train_df['combined_review'])\n",
    "X_train_pad = pad_sequences(sequences_train, maxlen=max_len, padding='post')\n",
    "\n",
    "# Tokenize and pad the test data\n",
    "sequences_test = tokenizer.texts_to_sequences(test_df['combined_review'])\n",
    "X_test_pad = pad_sequences(sequences_test, maxlen=max_len, padding='post')\n",
    "\n",
    "# Replace 'y_train' and 'y_test' with our labels\n",
    "y_train = train_df['sentiment'].replace({'positive': 2, 'neutral': 1, 'negative': 0})\n",
    "y_test = test_df['sentiment'].replace({'positive': 2, 'neutral': 1, 'negative': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nbvKVMR8QNP-",
    "outputId": "91418172-6740-40d0-eba2-65bcb953dd10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1665494, 3695940)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the required library\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Convert the sequences back to text\n",
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_reviews = [[reverse_word_index.get(i, '?') for i in sequence] for sequence in sequences_train]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "w2v_model = Word2Vec(decoded_reviews, vector_size=64, window=5, min_count=1, workers=4)\n",
    "w2v_model.train(decoded_reviews, total_examples=w2v_model.corpus_count, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQ2pEnpPRCxF"
   },
   "source": [
    "**Build the LSTM model:**\n",
    "Now, we will build the LSTM model that will use the word embeddings from the trained Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "rgJN5bFLQ6xt"
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=64, input_length=max_len))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvvcfLxNROfG"
   },
   "source": [
    "**Set the weights in the Embedding layer:**\n",
    "We now set the weights in the Embedding layer of the LSTM model to the word vectors obtained from the Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "hMZuVqp9RgCZ"
   },
   "outputs": [],
   "source": [
    "# Get the word vectors from the trained Word2Vec model\n",
    "embedding_matrix = np.zeros((5000, 64))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < 5000:\n",
    "        if word in w2v_model.wv:\n",
    "            embedding_matrix[i] = w2v_model.wv[word]\n",
    "\n",
    "# Use the word vectors as weights in the Embedding layer\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgAS640xRl1B"
   },
   "source": [
    "**Compile and train the LSTM model:**\n",
    "Finally, We compile the LSTM model and train it using the tokenized and padded training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "TQSlJgvYSNVI"
   },
   "outputs": [],
   "source": [
    "# Import the necessary library\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define the maximum length of a sequence\n",
    "max_len = 100\n",
    "\n",
    "# Tokenize and pad the training data\n",
    "sequences_train = tokenizer.texts_to_sequences(train_df['combined_review'])\n",
    "X_train_pad = pad_sequences(sequences_train, maxlen=max_len, padding='post')\n",
    "\n",
    "# Tokenize and pad the test data\n",
    "sequences_test = tokenizer.texts_to_sequences(test_df['combined_review'])\n",
    "X_test_pad = pad_sequences(sequences_test, maxlen=max_len, padding='post')\n",
    "\n",
    "# Replace 'y_train' and 'y_test' with our labels\n",
    "y_train = train_df['sentiment'].replace({'positive': 2, 'neutral': 1, 'negative': 0})\n",
    "y_test = test_df['sentiment'].replace({'positive': 2, 'neutral': 1, 'negative': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "Or1kciFFWa6l"
   },
   "outputs": [],
   "source": [
    "# Find the length of reviews\n",
    "review_length = [len(review) for review in sequences_train]\n",
    "\n",
    "# Find the maximum length\n",
    "max_len = max(review_length)\n",
    "\n",
    "# Now pad the sequences\n",
    "X_train_pad = pad_sequences(sequences_train, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(sequences_test, maxlen=max_len, padding='post')\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=64, input_length=max_len))  # Ensure `input_length=max_len`\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6zVJt2ORvtn",
    "outputId": "7d13651e-9c4c-4727-e94d-c6e3a54c6f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "98/98 [==============================] - 121s 1s/step - loss: 0.8829 - accuracy: 0.6759 - val_loss: 0.8981 - val_accuracy: 0.6467\n",
      "Epoch 2/5\n",
      "98/98 [==============================] - 127s 1s/step - loss: 0.8567 - accuracy: 0.6855 - val_loss: 0.8998 - val_accuracy: 0.6467\n",
      "Epoch 3/5\n",
      "98/98 [==============================] - 117s 1s/step - loss: 0.8572 - accuracy: 0.6855 - val_loss: 0.8980 - val_accuracy: 0.6467\n",
      "Epoch 4/5\n",
      "98/98 [==============================] - 128s 1s/step - loss: 0.8508 - accuracy: 0.6855 - val_loss: 0.8940 - val_accuracy: 0.6467\n",
      "Epoch 5/5\n",
      "98/98 [==============================] - 125s 1s/step - loss: 0.8521 - accuracy: 0.6855 - val_loss: 0.8958 - val_accuracy: 0.6467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26834286950>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_pad, y_train, epochs=5, validation_data=(X_test_pad, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oj97QKzkYvmw"
   },
   "source": [
    "**Evaluate the model:**\n",
    "After training the model, we can evaluate its performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxVXUTcpYwBD",
    "outputId": "2f23d63a-86a0-4698-bce8-029148906d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 13s 391ms/step - loss: 0.8958 - accuracy: 0.6467\n",
      "Test Loss: 0.9\n",
      "Test Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print('Test Loss: {}'.format(round(test_loss, 2)))\n",
    "print('Test Accuracy: {}'.format(round(test_accuracy, 2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZvNMuUfZUK_"
   },
   "source": [
    "It appears that our model has achieved an accuracy of approximately 65% on the test set, which is a reasonable starting point.\n",
    "\n",
    "However, the loss is still relatively high, which might suggest that the model could be further improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocHwitfJKY5-",
    "outputId": "5824109c-25c2-49c0-8e4d-1de8d00d8b17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 13s 390ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming y_pred_probs is our predicted probabilities for the test set\n",
    "y_pred_probs = model.predict(X_test_pad)\n",
    "\n",
    "# Use np.argmax to get class labels\n",
    "y_pred = np.argmax(y_pred_probs, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1mFqZ9qKgHL",
    "outputId": "e9e553d9-e9bf-455d-b9f0-18e66d9f8421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.00      0.00      0.00       169\n",
      "           2       0.65      1.00      0.79       670\n",
      "\n",
      "    accuracy                           0.65      1036\n",
      "   macro avg       0.22      0.33      0.26      1036\n",
      "weighted avg       0.42      0.65      0.51      1036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_test, y_pred, zero_division=0) # zero_division=0 to avoid warning.\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlM2t_IfYTkq"
   },
   "source": [
    "\n",
    "The results show that our model is classifying almost everything into the third class (label 2). This is evident from the recall of 1.00 for class 2, and 0.00 for the other two classes. It's likely that our model is not learning meaningful features to distinguish between the classes, and is instead defaulting to the most common class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       197\n",
      "           1       1.00      0.00      0.00       169\n",
      "           2       0.65      1.00      0.79       670\n",
      "\n",
      "    accuracy                           0.65      1036\n",
      "   macro avg       0.88      0.33      0.26      1036\n",
      "weighted avg       0.77      0.65      0.51      1036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "report = classification_report(y_test, y_pred, zero_division=1) # zero_division=1 results.\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
